{"meta":{"title":"Adopted Irelia","subtitle":"=w=","description":"homepage","author":"Adopted Irelia","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2024-09-09T15:38:31.486Z","updated":"2023-05-01T12:50:44.480Z","comments":true,"path":"aboutme/index.html","permalink":"http://example.com/aboutme/index.html","excerpt":"","text":""},{"title":"category","date":"2024-09-09T15:38:31.534Z","updated":"2023-04-28T09:02:35.290Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2024-09-09T15:38:31.519Z","updated":"2023-04-28T09:02:17.180Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"test","date":"2023-04-19T21:46:03.000Z","updated":"2023-04-20T12:21:52.000Z","comments":true,"path":"test/index.html","permalink":"http://example.com/test/index.html","excerpt":"","text":"haha"},{"title":"","date":"2024-09-09T15:38:30.470Z","updated":"2023-04-27T11:15:27.810Z","comments":true,"path":"mylist/index.html","permalink":"http://example.com/mylist/index.html","excerpt":"","text":""},{"title":"tags","date":"2024-09-09T15:38:31.471Z","updated":"2023-04-28T09:02:26.900Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Mac Things","slug":"mac/20240909-mac_things","date":"2024-09-09T04:00:00.000Z","updated":"2024-09-10T00:10:34.167Z","comments":true,"path":"2024/09/09/mac/20240909-mac_things/","link":"","permalink":"http://example.com/2024/09/09/mac/20240909-mac_things/","excerpt":"","text":"","categories":[{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"}]},{"title":"print colorful text in Python","slug":"tips/2024-04-24-colorfuloutput","date":"2024-04-24T04:00:00.000Z","updated":"2024-05-15T08:13:17.350Z","comments":true,"path":"2024/04/24/tips/2024-04-24-colorfuloutput/","link":"","permalink":"http://example.com/2024/04/24/tips/2024-04-24-colorfuloutput/","excerpt":"","text":"通过一些设置，可以通过python在控制台里输出不同颜色的内容 基本属性 显示方式 显示效果 0 默认值 1 高亮 4 下划线 5 闪烁 7 反显 8 不可见 控制台颜色值 前景色 背景色 颜色说明 30 40 黑色 31 41 红色 32 42 绿色 33 43 黄色 34 44 蓝色 35 45 紫红色 36 46 青蓝色 37 47 白色 语法 12# \\033[显示方式;前景色;背景色m****\\033[0mprint(&quot;\\033[1;33;44mhello world\\033[0m&quot;)","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"tools","slug":"tools","permalink":"http://example.com/tags/tools/"}]},{"title":"How to use gitignore","slug":"git_learn/2024-03-12-Usage_of_gitignore","date":"2024-03-12T04:00:00.000Z","updated":"2024-04-24T08:38:32.620Z","comments":true,"path":"2024/03/12/git_learn/2024-03-12-Usage_of_gitignore/","link":"","permalink":"http://example.com/2024/03/12/git_learn/2024-03-12-Usage_of_gitignore/","excerpt":"","text":"Introduction 在上传github文件的时候，可以使用gitignore忽略大文件的上传。 Usage 忽略优先级 从命令行中读取可用的忽略规则 当前目录定义的规则 父级目录定义的规则，依次递推 $GIT_DIR/info/exclude 文件中定义的规则 core.excludesfile中定义的全局规则 匹配文法 文法 1234567891011空格不匹配任意文件，可作为分隔符，可用反斜杠转义开头的文件标识注释，可以使用反斜杠进行转义! 开头的模式标识否定，该文件将会再次被包含，如果排除了该文件的父级目录，则使用 ! 也不会再次被包含。可以使用反斜杠进行转义/ 结束的模式只匹配文件夹以及在该文件夹路径下的内容，但是不匹配该文件/ 开始的模式匹配项目跟目录如果一个模式不包含斜杠，则它匹配相对于当前 .gitignore 文件路径的内容，如果该模式不在 .gitignore 文件中，则相对于项目根目录** 匹配多级目录，可在开始，中间，结束? 通用匹配单个字符* 通用匹配零个或多个字符[] 通用匹配单个字符列表 例子 123456789bin/: 忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件/bin: 忽略根目录下的bin文件/*.c: 忽略 cat.c，不忽略 build/cat.cdebug/*.obj: 忽略 debug/io.obj，不忽略 debug/common/io.obj 和 tools/debug/io.obj**/foo: 忽略/foo, a/foo, a/b/foo等a/**/b: 忽略a/b, a/x/b, a/x/y/b等!/bin/run.sh: 不忽略 bin 目录下的 run.sh 文件*.log: 忽略所有 .log 文件config.php: 忽略当前路径的 config.php 文件 可能遇到的问题 Q1 如果遇到gitignore无法忽略文件，则需要先删除本地缓存 123git rm -r --cached .git add .git commit -m &#x27;update .gitignore&#x27; Q2 如果想要添加某个文件但是发现被gitignore忽略了，可以使用-f强制添加 1git add -f App.class 或者通过check-ignore检查 1git check-ignore -v App.class","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"tools","slug":"tools","permalink":"http://example.com/tags/tools/"}]},{"title":"How to use vim","slug":"computer_learn/2024-03-12-Vim","date":"2024-03-12T04:00:00.000Z","updated":"2024-04-24T08:38:18.720Z","comments":true,"path":"2024/03/12/computer_learn/2024-03-12-Vim/","link":"","permalink":"http://example.com/2024/03/12/computer_learn/2024-03-12-Vim/","excerpt":"","text":"本篇主要通过vimtutor编辑，读者亦可直接在vimtutor里学习 基础操作 光标在屏幕文本中的移动既可以用箭头键，也可以使用 hjkl 字母键。 1h (左移) j (下行) k (上行) l (右移) 欲进入 Vim 编辑器(从命令行提示符)，请输入：vim 文件名 &lt;回车&gt; 欲退出 Vim 编辑器，请输入 &lt;ESC&gt; :q! &lt;回车&gt; 放弃所有改动。或者输入&lt;ESC&gt; :wq &lt;回车&gt;保存改动。 在正常模式下删除光标所在位置的字符，请按： x 欲插入或添加文本，请输入： 12i 输入欲插入文本 &lt;ESC&gt; 在光标前插入文本A 输入欲添加文本 &lt;ESC&gt; 在一行后添加文本 删除命令 欲从当前光标删除至下一个单词，请输入：dw 欲从当前光标删除至当前行末尾，请输入：d$ 欲删除整行，请输入：dd 欲重复一个动作，请在它前面加上一个数字：2w 在正常模式下修改命令的格式是： `operator [number] motion` 其中： operator - 操作符，代表要做的事情，比如 d 代表删除 [number] - 可以附加的数字，代表动作重复的次数 motion - 动作，代表在所操作的文本上的移动，例如 w 代表单词(word)， $ 代表行末等等。 欲移动光标到行首，请按数字0键：0 欲撤消以前的操作，请输入：u (小写的u) 欲撤消在一行中所做的改动，请输入：U (大写的U) 欲撤消以前的撤消命令，恢复以前的操作结果，请输入：CTRL-R 插入命令 要重新置入已经删除的文本内容，请按小写字母 p 键。该操作可以将已删除的文本内容置于光标之后。如果最后一次删除的是一个整行，那么该行将置于当前光标所在行的下一行。 要替换光标所在位置的字符，请输入小写的 r 和要替换掉原位置字符的新字符即可。 更改类命令允许您改变从当前光标所在位置直到动作指示的位置中间的文本。比如输入 ce 可以替换当前光标到单词的末尾的内容；输入 c$ 可以替换当前光标到行末的内容。 更改类命令的格式是： c [number] motion 替换命令 CTRL-G 用于显示当前光标所在位置和文件状态信息。 G 用于将光标跳转至文件最后一行。 先敲入一个行号然后输入大写 G 则是将光标移动至该行号代表的行。 gg 用于将光标跳转至文件第一行。 输入 / 然后紧随一个字符串是在当前所编辑的文档中正向查找该字符串。 输入 ? 然后紧随一个字符串则是在当前所编辑的文档中反向查找该字符串。 完成一次查找之后按 n 键是重复上一次的命令，可在同一方向上查 找下一个匹配字符串所在；或者按大写 N 向相反方向查找下一匹配字符串所在。 CTRL-O 带您跳转回较旧的位置，CTRL-I 则带您到较新的位置。 如果光标当前位置是括号(、)、[、]、&#123;、&#125;，按 % 会将光标移动到配对的括号上。 在一行内替换头一个字符串 old 为新的字符串 new，请输入 :s/old/new 在一行内替换所有的字符串 old 为新的字符串 new，请输入 :s/old/new/g 在两行内替换所有的字符串 old 为新的字符串 new，请输入 :#,#s/old/new/g 在文件内替换所有的字符串 old 为新的字符串 new，请输入 :%s/old/new/g 进行全文替换时询问用户确认每个替换需添加 c 标志 :%s/old/new/gc 在vim中执行外部命令 :!command 用于执行一个外部命令 command。 :w FILENAME 可将当前 VIM 中正在编辑的文件保存到名为 FILENAME 的文 件中。 v motion :w FILENAME 可将当前编辑文件中可视模式下选中的内容保存到文件 FILENAME 中。 :r FILENAME 可提取磁盘文件 FILENAME 并将其插入到当前文件的光标位置 后面。 :r !ls 可以读取 ls 命令的输出并将其放置到当前文件的光标位置后面。 插入 输入小写的 o 可以在光标下方打开新的一行并进入插入模式。 输入大写的 O 可以在光标上方打开新的一行。 输入小写的 a 可以在光标所在位置之后插入文本。 输入大写的 A 可以在光标所在行的行末之后插入文本。 e 命令可以使光标移动到单词末尾。 操作符 y 复制文本，p 粘贴先前复制的文本。 输入大写的 R 将进入替换模式，直至按 键回到正常模式。 输入 :set xxx 可以设置 xxx 选项。一些有用的选项如下： 1234567&#x27;ic&#x27; &#x27;ignorecase&#x27; 查找时忽略字母大小写&#x27;is&#x27; &#x27;incsearch&#x27; 查找短语时显示部分匹配&#x27;hls&#x27; &#x27;hlsearch&#x27; 高亮显示所有的匹配短语选项名可以用完整版本，也可以用缩略版本。 在选项前加上 no 可以关闭选项： :set noic","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"tools","slug":"tools","permalink":"http://example.com/tags/tools/"}]},{"title":"Computer Network Chapter 2","slug":"computer-network/cn2","date":"2023-06-13T04:00:00.000Z","updated":"2023-05-17T04:00:00.000Z","comments":true,"path":"2023/06/13/computer-network/cn2/","link":"","permalink":"http://example.com/2023/06/13/computer-network/cn2/","excerpt":"","text":"基本概念 应用层对应用程序的通信提供服务 功能 文件传输、访问和管理 FTP 电子邮件 SMTP,POP3 虚拟终端 HTTP 查询服务和远程作业登录 DNS 网络应用模型 网络应用模型包括C/S和P2P C/S: 客户服务器模型。 服务器是提供计算服务的设备 永久性的服务 永久性的访问地址/域名 客户是请求计算服务的设备 与服务通信，使用服务器的服务 间歇性介入网络 可能使用动态IP地址 不与其他客户机通信 P2P: peer to peer 每个主机既可以提供服务，也可以请求服务 任意节点之间可以直接通讯 节点间歇性接入网络 节点可能改变ip地址 可扩展性好 网络健壮性强 HTTP 端口80 C/S 状态码 1xx 表示通知信息，如请求收到了或在处理 2xx 表示成功，如接受或知道了 (200 OK 请求成功) 3xx 表示重定向，如要完成请求还必须采取进一步的行动 (301 Moved Permanently 请求的对象被永久转移，新的URL定义在响应报文的Location字段，客户将自动获取新的URL) 4xx 表示客户的差错 (400 Bad Request 该请求不能被服务器理解/404 Not Found 被请求的文档不在服务器上) 5xx 表示服务器的差错 (505 HTTP Version Not Support 服务器不支持对应的版本) SMTP 端口25 TCP C/S POP3 端口110 TCP C/S IMAP DNS 端口53 UDP DNS用来将域名映射为IP地址 域名 www.google.com .区分了标号，从右到左分别为顶级域名，二级域名，三级域名 域名服务器 当一台主机发出DNS查询请求时， FTP(File Transport Protocol) 端口21服务 端口20文件传送 带外 TCP C/S FTP提供不同种类主机系统之间的文件传输能力 TCP和UDP的Python代码实现 UDPclientUDPserver123456789101112131415161718192021222324252627from socket import *servername = &#x27;127.0.0.1&#x27;port = 50000# 创建UDP的socketclientsocket = socket(AF_INET,SOCK_DGRAM)#clientsocket.connect((servername,port))while True: message = input(&quot;&gt;&gt;&quot;) if message == &#x27;exit&#x27;: break clientsocket.sendto(message.encode(),(servername,port)) recved,addr = clientsocket.recvfrom(1024) # 如果返回空bytes，表示对方关闭了连接 if not recved: break # 打印读取的信息 print(recved.decode())clientsocket.close()12345678910111213141516171819202122232425262728from socket import *servername = &#x27;127.0.0.1&#x27;port = 50000# 创建UDP的socketserversocket = socket(AF_INET,SOCK_DGRAM)serversocket.bind((servername,port))#serversocket.listen(8)print(f&#x27;服务端启动成功，在&#123;port&#125;端口等待客户端连接...&#x27;)#dataSocket, addr = serversocket.accept()while True: recved,addr = serversocket.recvfrom(1024) print(f&quot;来自&#123;addr&#125;的信息&quot;) if not recved: break # 读取的字节数据是bytes类型，需要解码为字符串 info = recved.decode() print(f&#x27;收到对方信息： &#123;info&#125;&#x27;) # 发送的数据类型必须是bytes，所以要编码 serversocket.sendto(f&#x27;服务端接收到了信息 &#123;info&#125;&#x27;.encode(),addr)serversocket.close() TCPclientTCPserver1234567891011121314151617181920212223242526272829from socket import *IP = &#x27;127.0.0.1&#x27;SERVER_PORT = 50000# 实例化一个socket对象，指明协议dataSocket = socket(AF_INET, SOCK_STREAM)# 连接服务端socketdataSocket.connect((IP, SERVER_PORT))while True: # 从终端读入用户输入的字符串 toSend = input(&#x27;&gt;&gt;&#x27;) if toSend ==&#x27;exit&#x27;: break # 发送消息，也要编码为 bytes dataSocket.send(toSend.encode()) # 等待接收服务端的消息 recved = dataSocket.recv(1024) # 如果返回空bytes，表示对方关闭了连接 if not recved: break # 打印读取的信息 print(recved.decode())dataSocket.close()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 导入socket 库from socket import *import threadingimport time# 主机地址为空字符串，表示绑定本机所有网络接口ip地址# 等待客户端来连接IP = &#x27;127.0.0.1&#x27;# 端口号PORT = 50000# 实例化一个socket对象# 参数 AF_INET 表示该socket网络层使用IP协议# 参数 SOCK_STREAM 表示该socket传输层使用TCP协议listenSocket = socket(AF_INET, SOCK_STREAM)# socket绑定地址和端口listenSocket.bind((IP, PORT))# 使socket处于监听状态，等待客户端的连接请求# 参数 8 表示 最多接受多少个等待连接的客户端listenSocket.listen(8)print(f&#x27;服务端启动成功，在&#123;PORT&#125;端口等待客户端连接...&#x27;)def process(c, addr): n = 0 print(&#x27;接受一个客户端连接:&#x27;, addr) while True: # BUFLEN 指定从接收缓冲里最多读取多少字节 recved = dataSocket.recv(1024) # 如果返回空bytes，表示对方关闭了连接 # 退出循环，结束消息收发 if not recved: break # 读取的字节数据是bytes类型，需要解码为字符串 info = recved.decode() print(f&#x27;收到对方(&#123;addr&#125;)第&#123;n&#125;条信息： &#123;info&#125;&#x27;) n +=1 # 发送的数据类型必须是bytes，所以要编码 #time.sleep(1) dataSocket.send(f&#x27;服务端接收到了信息 &#123;info&#125;&#x27;.encode())while True: dataSocket, addr = listenSocket.accept() #创建线程使得多个连接可以实现 t = threading.Thread(target=process,args=(dataSocket,addr)) t.start()# 服务端也调用close()关闭socketdataSocket.close()listenSocket.close()","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Computer Network","slug":"Computer-Network","permalink":"http://example.com/tags/Computer-Network/"}]},{"title":"Dynamic Prototype Convolution Network for Few-Shot Semantic Segmentation","slug":"paper/2023-05-09-Dynamic Prototype Convolution Network for Few-Shot Semantic Segmentation","date":"2023-05-09T04:00:00.000Z","updated":"2023-05-09T04:00:00.000Z","comments":true,"path":"2023/05/09/paper/2023-05-09-Dynamic Prototype Convolution Network for Few-Shot Semantic Segmentation/","link":"","permalink":"http://example.com/2023/05/09/paper/2023-05-09-Dynamic%20Prototype%20Convolution%20Network%20for%20Few-Shot%20Semantic%20Segmentation/","excerpt":"(2022CVPR)Dynamic Prototype Convolution Network for Few-Shot Semantic Segmentation","text":"(2022CVPR)Dynamic Prototype Convolution Network for Few-Shot Semantic Segmentation Abstract Most existing FSS methods implement such support/query interactions by solely leveraging plain operations. we propose a dynamic prototype convolution network (DPCN) to fully capture the aforementioned intrinsic details for accurate FSS. Motivation However, the predictions achieved by solely relying on such limited prototypes and plain operations are inevitably losing some intrinsic object details in the query image. In FSS, it is usually difficult to comprehensively encode the adequate patterns of the target objects by solely considering the support information as in most previous prototype-based methods. Contribution We propose a dynamic prototype convolution network (DPCN) to capture the intrinsic object details for accurate FSS. To the best of knowledge, we are the first one to do this in the FSS domain. We propose a novel dynamic convolution module (DCM) to achieve adequate support-query interactions. DCM can serve as a plug-and-play component to improve existing prototype learning methods. We propose a support activation module (SAM) and a feature filtering module (FFM) to mine complementary information of target objects from query images. Method Support Activation Module (SAM) This module is used to generate an initial pseudo mask. first, we get the RsR_sRs​ and RqR_qRq​ Rs=W(xsh⊗Ms)∈Rdhdw×Ch×HsWsR_s = W(x_s^h \\otimes M_s) \\in R^{d_h d_w \\times C_h \\times H_s W_s} Rs​=W(xsh​⊗Ms​)∈Rdh​dw​×Ch​×Hs​Ws​ Rq=W(xqh)∈Rdhdw×Ch×HqWqR_q = W(x_q^h) \\in R^{d_h d_w \\times C_h \\times H_q W_q} Rq​=W(xqh​)∈Rdh​dw​×Ch​×Hq​Wq​ Then, We generate the final activation map Mact∈RHq×WqM_{act} \\in R^{H_q \\times W_q}Mact​∈RHq​×Wq​ by taking the mean value among all regions and the maximal value among all support features followed by normalization operation. Finally, we calculate the Mpes0∈RHq×WqM_{pes}^0 \\in R^{H_q \\times W_q}Mpes0​∈RHq​×Wq​ by a mean operation. Feature Filtering Module (FFM) This module aims to refine the pseudo mask and filter out irrelevant background information in the query feature. p=average(xs⊗R(Ms))p = average(x_s \\otimes R(M_s)) p=average(xs​⊗R(Ms​)) Then, we refine the pseudo mask Mpser=F((xq⊗R(Mpse0))⊕xp)M_{pse}^r = F((x_q \\otimes R(M_{pse}^0)) \\oplus x_p ) Mpser​=F((xq​⊗R(Mpse0​))⊕xp​) finally, the output is x~q=(xq⊗Mpser)⊕xq\\widetilde{x}_q = (x_q \\otimes M_{pse}^r) \\oplus x_q xq​=(xq​⊗Mpser​)⊕xq​ Dynamic Convolution Module (DCM) This module aims to incorporate relevant contextual information. We calculate the prototype of foreground Pfg=Fe(xs⊗Ms)∈RNfg×CP_{fg} = F_e(x_s \\otimes M_s) \\in R^{N_{fg} \\times C} Pfg​=Fe​(xs​⊗Ms​)∈RNfg​×C Then, we put the prototype into 1D pooling ps=pools(Pfg),ps2=pools2(ps)p_s = pool_s(P_{fg}), p_{s^2} = pool_{s^2}(p_s) ps​=pools​(Pfg​),ps2​=pools2​(ps​) Then, we generate the kernel weights kerv=Fconv1(ps)ker_v = F_{conv1}(p_s) kerv​=Fconv1​(ps​) kerh=Fconv1(ps)ker_h = F_{conv1}(p_s) kerh​=Fconv1​(ps​) kers=Fconv1(ps2)ker_s = F_{conv1}(p_{s^2}) kers​=Fconv1​(ps2​) then, we can get the output through dynamic convolutions x~qv=Fdc(x~q∣kerv)\\widetilde{x}_q^v = F_{dc}(\\widetilde{x}_q | ker_v) xqv​=Fdc​(xq​∣kerv​) xout=Fcat(x~qv,x~qh,x~qs,xp,{Macti}i=13,Mpser)x_{out} = F_{cat}(\\widetilde{x}_q^v,\\widetilde{x}_q^h,\\widetilde{x}_q^s,x_p,\\{M_{act}^i\\}^3_{i=1},M_{pse}^r) xout​=Fcat​(xqv​,xqh​,xqs​,xp​,{Macti​}i=13​,Mpser​) the final mask is M^q=Fcls(FASPP(Fconv(xout)))\\hat{M}_q =F_{cls}(F_{ASPP}(F_{conv}(x_{out}))) M^q​=Fcls​(FASPP​(Fconv​(xout​))) Conclusion We propose a dynamic prototype convolution network (DPCN) with three major components (i.e., SAM, FFM, and DCM) to address the challenging FSS task. To better mine information from query image, we propose SAM and FFM to generate pseudo query mask and filter background information, respectively. Moreover, a plug-and-play module DCM is designed to implement sufficient interaction between support and query features.","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Few Shot","slug":"Few-Shot","permalink":"http://example.com/tags/Few-Shot/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","permalink":"http://example.com/tags/Semantic-Segmentation/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://example.com/tags/Computer-Vision/"}]},{"title":"Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation","slug":"paper/2023-04-20-Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation","date":"2023-04-20T04:00:00.000Z","updated":"2023-05-06T03:49:36.950Z","comments":true,"path":"2023/04/20/paper/2023-04-20-Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation/","link":"","permalink":"http://example.com/2023/04/20/paper/2023-04-20-Intermediate%20Prototype%20Mining%20Transformer%20for%20Few-Shot%20Semantic%20Segmentation/","excerpt":"(2022NeurIPS)Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation","text":"(2022NeurIPS)Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation Abstract Most previous works strive to mine more effective category information from the support to match with the corresponding objects in query. However, they all ignored the category information gap between query and support images. we are the first to introduce an intermediate prototype for mining both deterministic category information from the support and adaptive category knowledge from the query Motivation However, for the support images that have large diversity in pose and appearance compared with the query, the distance between the support and query prototypes will be faraway. In such a case, if we forcibly migrate the category information in the support prototype to the query, a large category information bias is inevitably introduced. Contribution To the best of our knowledge, this is the first time to focus on the intra-class diversity between support and query in FSS, and we propose the idea of intermediate prototype to relieve the existing category information gap issue. We propose a novel IPMT to explicitly mine the intermediate prototype which contains both the deterministic information from the support set and the adaptive category knowledge from the query We present an iterative learning scheme to fully explore the intermediate category information hidden in both support and query and update the query feature. Extensive experiments on PASCAL-5i and COCO-20i show that our proposed IPMT brings a significant improvement over state-of-the-art methods. Method Intermediate Prototype Mining G is global prototype as context. IPM(G,Fs,Fq,Ms,Pq)=MLP(MaskAttn(G,Fs,Ms)+MaskAttn(G,Fq,Pq)+G)IPM(G, F^s, F^q, M^s, P^q) = MLP(MaskAttn(G, F^s, M^s) + MaskAttn(G, F^q, P^q) + G) IPM(G,Fs,Fq,Ms,Pq)=MLP(MaskAttn(G,Fs,Ms)+MaskAttn(G,Fq,Pq)+G) G can be updated through the equation above. Query Activation After every iteration, we need to activate the output. QA(G,Fq)=Factv(G⋅Fq)QA(G,F^q) = F_{actv}(G \\cdot F^q) QA(G,Fq)=Factv​(G⋅Fq) Duplex Segmentation Loss We calculate the loss through MG(G,Fq)=Sigmoid(GWm(Fq)T)MG(G,F^q) = Sigmoid(GW_m(F^q)^T) MG(G,Fq)=Sigmoid(GWm​(Fq)T) MG(G,Fs)=Sigmoid(GWm(Fs)T)MG(G,F^s) = Sigmoid(GW_m(F^s)^T) MG(G,Fs)=Sigmoid(GWm​(Fs)T) Iterative Prototype Mining We can update the G through Gl=IPM(Gl−1,Fs,Fl−1q,Ms,Pl−1q)G_l = IPM(G_{l-1}, F^s, F^q_{l-1}, M^s, P^q_{l-1}) Gl​=IPM(Gl−1​,Fs,Fl−1q​,Ms,Pl−1q​) We can update feature Flq=QA(Gl,Fl−1q)F_l^q = QA(G_l, F_{l-1}^q) Flq​=QA(Gl​,Fl−1q​) We can update query mask P Plq=MG(Gl,Fl−1q)&gt;0.5P^q_l = MG(G_l,F^q_{l-1})&gt;0.5 Plq​=MG(Gl​,Fl−1q​)&gt;0.5 Conclusion we focus on the intra-class diversity between query and support and introduce an intermediate prototype to bridge the category information gap between them. The core idea is to use the intermediate prototype to aggregate the support-deterministic and query-adaptive category information by our designed Intermediate Prototype Mining Transformer (IPMT) in an iterative way.","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Few Shot","slug":"Few-Shot","permalink":"http://example.com/tags/Few-Shot/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","permalink":"http://example.com/tags/Semantic-Segmentation/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://example.com/tags/Computer-Vision/"}]},{"title":"CATrans:Context and Affinity Transformer for Few-Shot Segmentation","slug":"paper/2023-04-21-CATrans: Context and Affinity Transformer for Few-Shot Segmentation","date":"2023-04-20T04:00:00.000Z","updated":"2023-05-06T04:00:00.000Z","comments":true,"path":"2023/04/20/paper/2023-04-21-CATrans: Context and Affinity Transformer for Few-Shot Segmentation/","link":"","permalink":"http://example.com/2023/04/20/paper/2023-04-21-CATrans:%20Context%20and%20Affinity%20Transformer%20for%20Few-Shot%20Segmentation/","excerpt":"(2022ICJAI)CATrans:Context and Affinity Transformer for Few-Shot Segmentation","text":"(2022ICJAI)CATrans:Context and Affinity Transformer for Few-Shot Segmentation Abstract previous Transformer-based methods explore global consensus either on context similarity or affinity map between support-query pairs we effectively integrate the context and affinity information via the proposed novel Context and Affinity Transformer (CATrans) in a hierarchical architecture. Motivation (context)This method, however, suffers from unrepresentative of support feature. (affinity)However, this method does not incorporate individual self-affinity for support object or query image to disambiguate noisy correlations, which measures pixel-wise correspondences within itself, enabling each spatial fiber to match itself and other tokens. Contribution We design a Relation-guided Context Transformer (RCT) with the enhanced support features to propagate informative semantic information from support to query images. We develop a Relation-guided Affinity Transformer (RAT) to measure the reliable cross correspondences by considering the auxiliary self-affinity of both support object and query images. We propose Context and Affinity Transformer, dubbed as CATrans, in a hierarchical architecture to aggregate the context and affinity together, resulting in discriminative representations from support to query mask, enhancing robustness to intra-class variations between support and query images. Our CATrans outperforms the state-of-the-art methods on two benchmarks, Pascal-5i and COCO-20i. Method Relation-guided Context Transformer We first calculate the self-context Cssl=MLP(LN(MHA(Fsl,Fsl,Fml)))C_{ss}^l = MLP(LN(MHA(F_s^l,F_s^l,F_m^l))) Cssl​=MLP(LN(MHA(Fsl​,Fsl​,Fml​))) Cqql=MLP(LN(MHA(Fql,Fql,Fql)))C_{qq}^l = MLP(LN(MHA(F_q^l,F_q^l,F_q^l))) Cqql​=MLP(LN(MHA(Fql​,Fql​,Fql​))) Then, we can calculate the cross-context Csql=MLP(LN(MHA(Cqql,Fsl,Cssl)))C_{sq}^l = MLP(LN(MHA(C_{qq}^l,F_s^l,C_{ss}^l))) Csql​=MLP(LN(MHA(Cqql​,Fsl​,Cssl​))) Relation-guided Affinity Transformer We first calculate the self-affinity,we need to enable each pixel-wise feature belonging to itself to match pixel-wise feature at the same position, making it robust to large variations in object appearance between the support and query images. Assl=softmax((fml∣∣fsl)Wq⋅((fml∣∣fsl)Wk)TCl+Cml)A_{ss}^l = softmax(\\frac{(f_m^l||f_s^l)W_q \\cdot ((f_m^l||f_s^l)W_k )^T}{\\sqrt{C_l + C_m^l}}) Assl​=softmax(Cl​+Cml​​(fml​∣∣fsl​)Wq​⋅((fml​∣∣fsl​)Wk​)T​) Aqql=softmax(fqlWq⋅(fqlWk)TCl)A_{qq}^l = softmax(\\frac{f_q^l W_q \\cdot (f_q^lW_k )^T}{\\sqrt{C_l}}) Aqql​=softmax(Cl​​fql​Wq​⋅(fql​Wk​)T​) Then, we calculate the cross-affinity Asql=softmax(fqlWq⋅(fslWk)TCl)A_{sq}^l = softmax(\\frac{f_q^l W_q \\cdot (f_s^lW_k )^T}{\\sqrt{C_l}}) Asql​=softmax(Cl​​fql​Wq​⋅(fsl​Wk​)T​) The final output is final=MLP(LN(MHA(Asql,Assl,Asql)+Aqql))final = MLP(LN(MHA(A_{sq}^l,A_{ss}^l,A_{sq}^l)+A_{qq}^l)) final=MLP(LN(MHA(Asql​,Assl​,Asql​)+Aqql​)) Conclusion Different from previous approaches that either build on context or affinity between support and query image, our CATrans effectively incorporate both measures for query segmentation In addition, we consider pixel-wise correspondences for individual support and query features to disambiguate noisy correlations.","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Few Shot","slug":"Few-Shot","permalink":"http://example.com/tags/Few-Shot/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","permalink":"http://example.com/tags/Semantic-Segmentation/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://example.com/tags/Computer-Vision/"}]},{"title":"a simple way to try on your mysql","slug":"databse/2023-03-16-databse","date":"2023-03-16T04:00:00.000Z","updated":"2023-06-11T11:28:07.370Z","comments":true,"path":"2023/03/16/databse/2023-03-16-databse/","link":"","permalink":"http://example.com/2023/03/16/databse/2023-03-16-databse/","excerpt":"","text":"the whole relationship is like this: graph LR; A[database] --> B(schema) B --> C(table) B --> D(view) C --> E(index) database create 1create database &lt;your database name&gt; schema create 1create schema &lt;your schema name&gt; However, in mysql, it seems that database and schema is the same thing. table before creating a table, you need to use command use to choose your schema. 1use &lt;your schema name&gt; create 12345create table &lt;your table name&gt;( name type [condition], name type [condition], ...) the condition can be filled with: condition explanation primary key 主键，可以唯一标识对应的记录 foreign key 外键，与某表的主键相连 not null 属性不能为空 unique 属性的值是唯一的 auto_increment 属性值自动增加 default 默认值 check 自定义(记得加括号) you can choose different types like: type explanation int 长整数 smallint 短整数 numeric(p,d) 定点数，共p位，右面d位 real 浮点数 double 双精度 float 浮点数 char(n) 固定长度n的字符串 varchar(n) 可变长度字符串，最大为n data 日期（年，月，日） time 时间（时，分，秒） text 文本 12345678910create table &lt;your table name&gt;( ... primary key(name1,name2), foreign key(name3) references table0(name4) on delete cascade/no action on update cascade/no action, check (length(name)&lt;1) ) this command means that the primary key of table is (name1,name2), and it refers to another table table0. modify 12345678alter table &lt;your table name&gt;add [column] &lt;new col name&gt; &lt;type&gt; [condition]add &lt;condition&gt;drop [column] &lt;ori col name&gt; [cascade|restrict]alter column &lt;ori col name&gt; &lt;type&gt;rename to &lt;new table name&gt;change &lt;origin col name&gt; &lt;new col name&gt; &lt;type&gt; modify &lt;col name&gt; &lt;type&gt; delete 1drop table &lt;your table name&gt; [restrict|cascade] constrain 1constrain &lt;constrain name&gt; &lt;constrain condition&gt; index create 1create [unique] [cluster] index &lt;index name&gt; modify 1alter index &lt;old name&gt; rename to &lt;new name&gt; delete 1drop index &lt;name&gt; view create 123create view &lt;name&gt;as &lt;select ...&gt;[with check option] delete 1drop view &lt;name&gt; select generally, the command is like: 12345select [all|distinct] &lt;column&gt; [,&lt;column&gt;]from &lt;table&gt; [,&lt;table&gt;] [where &lt;condition&gt;][group by &lt;column&gt; [having &lt;condition&gt;]][order by &lt;column&gt; [asc|desc]] distinct means there is no repeat in data. select 12select Sno,Snamefrom Student; where conditions include: 条件 谓词 比较 =,&gt;,&lt;,&gt;=,&lt;=,!=,&lt;&gt;,!&gt;,!&lt;,NOT … 确定范围 between … and …, not between … and … 确定集合 in, not in 字符匹配 like, not like 空 is null, is not null 多重条件 and, or, not 123select Snamefrom studentwhere Sno = 123; 通配符中，%代表任意长度的字符，_表示单个长度的字符，如果有字符占用了通配符可以用escape来防止这种情况 123select Cnofrom Coursewhere Cname like &#x27;DB\\_Desgin&#x27; escape &#x27;\\&#x27;; order 1234select Snofrom scwhere cno=&#x27;3&#x27;order by grade desc; desc 表示降序，默认是升序 gather command explanation count(*) 统计元组个数 count([distinct|all] ) as … 统计一列中值的个数 sum([distinct|all] ) as … 求和 avg([distinct|all] ) as … 均值 max([distinct|all] ) as … 最大 min([distinct|all] ) as … 最小 12select count(*)from sc; group 1234select avg(grade) as 平均分from scgroup by snohaving count(*)&gt;3; the command outputs the average grade of every student and they take more than 3 courses. UNION, INTERSECT, EXCEPT 123456789select *from Swhere Sdept =&#x27;CS&#x27;[UNION/INTERSECT/EXCEPT]select *from Swhere Sage &gt; 19 UNION, INTERSECT, EXCEPT 分别代表并集，交集，差集 derived table 123SELECT Sno,Cnofrom SC, (select Sno,Avg(Grade) from SC group by Sno) as avg_sc(avg_sno,avg_grade)where SC.sno = avg_sc.avg_sno and SC.grade &gt;= avg_sc.avg_grade select data in more than 1 table connect with others 123select S.sno,sname,cno,gradefrom S, SCwhere S.sno = SC.sno and grade=95; connect with self 123select X.snofrom SC as X, SC as YWhere X.sno=Y.sno and X.cno=&#x27;c2&#x27; and Y.cno=&#x27;c3&#x27; This command rename a table to make it connect with itself. out join 12select snofrom s outer join sc on s.sno=sc.no sub-select unrelated 12345678select snamefrom swhere sno in( select sno from sc where cno=&#x27;c2&#x27;) 不相关子查询中，子查询独立执行，只需执行一次，与父查询无关. related 12345678select sno,snamefrom swhere exists( select * from sc where s.no=sc.sno and grade=95) 相关子查询中，子查询多次运行，与父查询有关. insert data insert 12insert into S(sno,sname,age)values(&#x27;s1&#x27;,&#x27;li&#x27;,19) 12insert into Svalues(&#x27;s1&#x27;,&#x27;li&#x27;,19,&#x27;male&#x27;) 12insert into &lt;table name&gt; [column1,column2,...]select ... this command create a new table by selecting data from table. modify 123update &lt;table name&gt;set &lt;column&gt; = ... [where] where means you can modify certain column. delete 123delete from &lt;table name&gt;[where] delete more than 2 tables is not allowed where means you can delete certain data. security create a new user 1create user &#x27;new_username&#x27;@&#x27;localhost&#x27; identified by &#x27;password&#x27; you can create a new user named new_username by the above command. then accredit the user 12345grand &lt;privilege&gt;[,&lt;privilege&gt;] [on &lt;database&gt;.&lt;table&gt;] to &lt;user_name&gt;[,&lt;user_name&gt;] [with grant option];grant select, insert, update, delete on database_name.table_name to &#x27;username&#x27;@&#x27;localhost&#x27;;grant all privileges on database_name.* to &#x27;username&#x27;@&#x27;localhost&#x27;; finally, flush the mysql 1flush privileges; role 1create role &lt;role name&gt; create a role 123grant &lt;privilege&gt;[,&lt;privilege&gt;]on &lt;data type&gt; data_nameto &lt;role&gt;,[,&lt;role&gt;] grant the privilege to a role 12grant &lt;role&gt;[,&lt;role&gt;]to &lt;role&gt;[,&lt;user&gt;] trigger create 1234567create trigger &lt;name&gt;&#123;before|after&#125; &lt;event&gt; on &lt;table name&gt;for each &#123;row|statement&#125;[when&lt;event&gt;]begin&lt;movement&gt;end this command create a trigger delete 1drop trigger &lt;trigger name&gt; this command delete a trigger Procedure create 1234CREATE PROCEDURE procedure_name ([parameter1 datatype1, parameter2 datatype2, ...])BEGIN -- your codeEND; This command creates a procedure of MySQL. delete 1drop procedure procedure_name This command delete a procedure. execute 1call procedure_name pymysql you can also use python to connect to mysql and execute some commands like inserting or selecting. first, install the package 1pip install pymysql then, you can execute command like this 123456789101112131415161718192021222324import pymysql# connect to mysqldb = pymysql.connect( host=&#x27;localhost&#x27;, user=&#x27;root&#x27;, password=&#x27;your password&#x27;, database=&#x27;your database name&#x27;)# create a cursorcursor = db.cursor()# run command with cursorcursor.execute(&quot;show databases&quot;)# data is the return of the commanddata = cursor.fetchall()# let database execute the commanddb.commit()# close the databasedb.close()","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"How to run your code without fixing at your terminal","slug":"tmux-and-screen/2023-03-10-tmux_and_screen","date":"2023-03-10T05:00:00.000Z","updated":"2023-04-27T10:49:54.410Z","comments":true,"path":"2023/03/10/tmux-and-screen/2023-03-10-tmux_and_screen/","link":"","permalink":"http://example.com/2023/03/10/tmux-and-screen/2023-03-10-tmux_and_screen/","excerpt":"","text":"introduction We may encounter a situation that when we want to run a code on the server, it takes a long period of time to finish. However, if we want to shut down the server, the code will be killed. Fortunately, there are two ways to solve the problem. The first is tmux command and the second is screen command. This blog will introduce the usage of two commands. screen show 1screen -ls This command is to show the status of screens. btw, 29281 means {pid}, zdj means task_name create 123screen -S &#123;task_name&#125;screen the first command can create a new screen on the terminal with your task_name for recognizing. The second command can create a new screen on the terminal with fault name. detach 123screen -d &#123;pid&#125;screen -d &#123;task_name&#125; reattach 123screen -r &#123;pid&#125;screen -r &#123;task_name&#125; delete task if you want to delete a task, what you need to do is reattach task and input exit in the terminal window. tmux show 1tmux ls create 123tmuxtmux new -s &#123;session_name&#125; detach 1tmux detach reattach 1tmux attach -t &#123;session_name&#125; delete 1tmux kill-session -t &#123;session_name&#125;","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"}]},{"title":"Few-Shot Segmentation via Cycle-Consistent Transformer","slug":"paper/2023-03-08-Few-Shot Segmentation via Cycle-Consistent Transformer","date":"2023-03-08T05:00:00.000Z","updated":"2023-05-06T03:21:00.240Z","comments":true,"path":"2023/03/08/paper/2023-03-08-Few-Shot Segmentation via Cycle-Consistent Transformer/","link":"","permalink":"http://example.com/2023/03/08/paper/2023-03-08-Few-Shot%20Segmentation%20via%20Cycle-Consistent%20Transformer/","excerpt":"(2021NeurIPS)Few-Shot Segmentation via Cycle-Consistent Transformer","text":"(2021NeurIPS)Few-Shot Segmentation via Cycle-Consistent Transformer Abstract In this paper, we focus on utilizing pixel-wise relationships between support and query images to facilitate the few-shot semantic segmentation. Directly performing cross-attention may aggregate these features from support to query and bias the query features. Thus, we propose using a novel cycle-consistent attention mechanism to filter out possible harmful support feature and encourage query features to attend to the most informative pixels from support images. Motivation class-wise mean pooling (a). support features within regions of different categories are averaged to serve as prototypes to facilitate the classification of query pixels. clustering (b). recent works attempt to generate multiple prototypes via EM algorithm or K-means clustering, in order to extract more abundant information from support images. these prototype-based methods need to “compress” support information into different prototypes, which may lead to various degrees of loss of beneficial support information. © propose to employ the attention mechanism to extract information from foreground. However, such methods ignore background support pixels that can be beneficial for segmenting query images. Contribution We tackle few-shot semantic segmentation from the perspective of providing each query pixel with relevant information from support images through pixel-wise alignment We propose a novel cycle-consistent transformer to aggregate the pixel-wise support features into the query ones. In CyCTR, we observe that many support features may confuse the attention ans bias pixel-level feature aggregation, and propose incorporating cycle-consistent operation into the attention to deal with this issue. Our CyCTR achieves state of art. Method Cycle-Consistent Transformer Cycle-Consistent Attention this module is used to identify cycle-consistent. first, find the most similar i from j. i∗=arg⁡max⁡θA(i,j)i^* = \\mathop{\\arg\\max}\\limits_{\\theta} A_{(i,j)} i∗=θargmax​A(i,j)​ then, cycle back. j∗=arg⁡max⁡θA(i∗,j)j^* = \\mathop{\\arg\\max}\\limits_{\\theta} A_{(i^*,j)} j∗=θargmax​A(i∗,j)​ if Ms(j)=Ms(j∗)M_{s(j)} = M_{s(j^*)}Ms(j)​=Ms(j∗)​, we accept the cycle-consistent. Bj={0,ifMs(j)=Ms(j∗)−inf,ifMs(j)≠Ms(j∗)B_j = \\begin{cases} 0, if M_{s(j)} = M_{s(j^*)} \\\\ -inf, if M_{s(j)} \\neq M_{s(j^*)} \\end{cases} Bj​={0,ifMs(j)​=Ms(j∗)​−inf,ifMs(j)​=Ms(j∗)​​ so the final attention is Cycleatt(Q,K,V)=softmax(Ai+B)VCycleatt(Q,K,V) = softmax(A_i + B)V Cycleatt(Q,K,V)=softmax(Ai​+B)V it means when B is not cycle-consistent, then we pay no attention to B. Conclusion our CyCTR utilizes all pixel-level support features and can effectively eliminate aggregating confusing and harmful support features with the proposed novel cycle-consistency attention","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Few Shot","slug":"Few-Shot","permalink":"http://example.com/tags/Few-Shot/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","permalink":"http://example.com/tags/Semantic-Segmentation/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://example.com/tags/Computer-Vision/"}]},{"title":"Computer Network Chapter 1","slug":"computer-network/2023-03-06-computer-network","date":"2023-03-06T05:00:00.000Z","updated":"2023-05-18T03:53:41.830Z","comments":true,"path":"2023/03/06/computer-network/2023-03-06-computer-network/","link":"","permalink":"http://example.com/2023/03/06/computer-network/2023-03-06-computer-network/","excerpt":"","text":"什么是因特网 构成描述 所有与互联网相连接的设备(手机、电脑、平板、桌面PC、Linux工作站、服务器等)都称为 主机(host) 或 端系统(end system) 。 端系统会通过 通信链路(communication link) 和 分组交换机(packet switch) 连接到一起。通信链路包括同轴电缆、铜线、光纤等。当今的分组交换机包括 路由器(router) 和 链路层交换机(link-layer switch) 端系统通过 因特网服务提供商(Internet Service Provider, ISP) 接入因特网。 端系统、分组交换机和其他部件都要运行一系列 协议(protocol) 这些协议控制因特网中信息的接受和发送，因特网的主要协议统称为 TCP/IP 协议。 服务描述 与因特网相连的端系统提供了一个 套接字接口 ，该接口规定了运行在一个端系统上的程序和另一个端系统交付数据的方式。 网络边缘 网络边缘就是我们常用的计算机、手机或是其他设备 接入网 家庭接入:DSL、电缆、FTTH、拨号和卫星 宽带住宅接入主要有两种方式，数字用户线(Digital Subscriber Line,DSL) 和电缆。 所以用户在使用DSL的时候，本地的电话公司也是他的ISP。 除了DSL，还有一种新型技术，叫做光纤到户(Fiber to The Home,FTTH)。 企业接入:以太网和WiFi 在公司和大学校园以及越来越多的家庭环境中，使用局域网将端系统连接到边缘路由器。但是注意，WLAN用户必须在接入点的几十米范围内。 广域无限接入:3G和LTE 对于移动设备应用的普及，可以通过蜂窝网提供商运营的基站发送分组，和WiFi不同的时，用户只需要在基站的数万米之内。 物理媒体 物理媒体分为 导引型媒体 如光缆，双绞铜线，同轴电缆 和 非导引型媒体 如无线局域网和数字卫星频道。 网络核心 分组交换 在各种网络应用中，端系统彼此交换报文。在交换中，分组以等于该链路最大 传输速率 的速度传输通过通信链路，加入源端系统或者分组交换机经过一条链路发送一个 L bitL \\ bitL bit 的分组，链路的传输速率为 R bit/sR \\ bit/sR bit/s 那么传输分组的时间为 L/R sL/R \\ sL/R s 存储转发传输 在分组到达路由器的时候，必须一整个分组全部被接收，路由器才会继续向目的地发送该分组。 比如，在时刻0的时候开始传输分组，在 L/R sL/R \\ sL/R s 时，路由器才收到整个分组，在 2L/R s2L/R \\ s2L/R s 时，路由器才发送完了所有的分组，总时延就为 2L/R s2L/R \\ s2L/R s 。 考虑一个一般的情况，某个长为 L bitL \\ bitL bit 的分组通过由 RRR 条速率均为 R bit/sR \\ bit/sR bit/s 的链路组成的路径，那么总延迟为: dendtoend=NLRd_{endtoend} = N \\frac{L}{R} dendtoend​=NRL​ 排队时延和分组丢失 每台分组交换机都有多条链路连接，对于每条链路他都有一个 输出缓存(output buffer) ，如果一个分组到达，他发现链路正在忙于传输其他分组，则该分组必须在缓存中等待，所以除了存储转发时延，分组还需要承受 排队时延(queuing delay) ，如果分组到来的时候缓存满了，则会发生分组丢失。 转发表和路由选择协议 每一台路由器都通过 转发表(forwarding table) 来决定将分组传输到哪个位置，他可以将目的地址映射为输出链路。因特网具有一些特殊的 路由选择协议(routing protocol) 来设置这些转发表 电路交换 在电路交换中，预留了路径通信中所需要的资源，而在分组交换中没有预留。 电路交换中的复用 链路中的交换是通过 频分复用(Frequency-Division Multiplexing) 或 时分复用(Time-Division Multiplexing) 来实现的。 分组交换和电路交换的对比 example1: 假设多个用户共享一个 1 Mbps1 \\ Mbps1 Mbps 的链路，如果用户以 100 kbps100 \\ kbps100 kbps 的速率产生数据，并且只有 1010%10 的时间活跃，对于电路交换，则在所有的时间内必须给用户预留 100kbps100kbps100kbps ，所以电路交换只能支持10个并发的用户，而对于分组交换，由于同时由10个以上的用户共同传输的概率极低，所以此例中分组交换和电路交换的速率接近。 example2: 假设刚刚所说的用户中有一个用户突然产生 100010001000 个 1000 bit1000 \\ bit1000 bit 的分组，其他用户不活跃，那么电路交换则需要 10 s10 \\ s10 s时间，但是分组交换只需要 1 s1 \\ s1 s 即可。 网络的网络 分组交换网中的时延、丢包和吞吐量 时延的概述 时延主要分为 节点处理时延(nodal processing delay) ， 排队时延(queuing delay) ， 传输时延(transmission delay) , 传播时延(propagation delay) 处理时延： 检查分组首部和决定将分组导向何处所需的时间是它的一部分，他还能包括其他因素比如检查比特级别的差错需要的时间。将这些处理后，路由器将分组引入通过链路的队列。 排队时延： 分组在链路上等待的时间即为排队时延。 传输时延： 从路由器A到路由器B的链路的传输时间，或者说将分组推向链路所需要的时间。 传播时延： 传播时延主要指的是在物理媒体传播需要的时间。 排队时延和丢包 令 aaa 表示分组到达队列的平均速率， RRR 表示传输速率， 那么比特到达队列的速率为 La bpsLa \\ bpsLa bps, 那么 /fracLaR/frac{La}{R}/fracLaR 被称为流量强度，若其大于1，则队列会趋向于无限增加。 同理，如果他越接近1，那么时延将会越高。 其他性能指标 带宽： 从某点到另一点能通过的最高数据率 吞吐量： 单位时间内通过某个网络的数据量 时延带宽积： 时延 x 带宽， 表示在某条链路上总的比特数 RTT： 从发送方收到到接收方确认共经历的时延 协议层次及其服务模型 上图是五层结构，下图是每层结构的处理","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Computer Network","slug":"Computer-Network","permalink":"http://example.com/tags/Computer-Network/"}]},{"title":"How to use docker on Macbook","slug":"docker/2023-03-02-docker","date":"2023-03-02T05:00:00.000Z","updated":"2023-04-27T10:48:58.280Z","comments":true,"path":"2023/03/02/docker/2023-03-02-docker/","link":"","permalink":"http://example.com/2023/03/02/docker/2023-03-02-docker/","excerpt":"","text":"参考文章：https://docker.easydoc.net/doc/81170005/cCewZWoN/XQEqNjiu 简介 打包：将所需要的依赖，第三方库，软件打包到一块，变成一个安装包 安装包：将安装包上传到一个镜像仓库，其他人可以方便地获取 部署：拿着安装包就可以用一个命令行运行，自动模拟出一摸一样的环境 优势 方便传给别人安装 快速安装软件 多个版本软件共存 安装软件 在官网对应的仓库找到对应的软件，运行命令： 1docker run -itd -p 6379:6379 [-p xxx:xxx] [--platform ...] [--network ...] [--privileged=true] [--hostname ...]--name redis redis:latest -i 表示交互模式 -t 表示终端交互 -d 表示后台运行 -p 表示端口号 –platform 表示选择不同的架构 –network 表示选择网络，可选bridge,host等 –privileged 表示启用root特权 –name名字 最后表示版本号 镜像保存 通过 1docker ps -a 知道某个容器的id，然后通过 1docker commit -m=... -a=... &lt;容器id&gt; &lt;image name&gt; 保存成压缩包 1docker save -o &lt;xx.tar&gt; &lt;image name&gt; 把压缩包导入成镜像 1docker load &lt; &lt;xxx.tar&gt; 制作自己的镜像image 编写Dockerfile 123456789FROM &lt;image&gt;:&lt;tag&gt; #选一个镜像MAINTAINER &lt;name&gt; #维护者信息ADD &lt;src&gt; &lt;dest&gt; #本地文件映射到对应的目录WORKDIR &lt;add&gt; #设置工作目录RUN &lt;command&gt; #执行的命令CMD &lt;command&gt; #构建镜像后调用的命令 运行自己的Dockerfile： 1docker build -t test:v1 -t表示设置版本号和名字 1docker run -p 主机：容器 目录挂载 bind mount 方式: 1docker run -v &lt;local&gt;:&lt;des&gt; volume 方式： 1docker run -v db-data:&lt;des&gt; Docker-compose 需要先编写一个docker-compose.yml的文件 1234567891011121314151617181920version: &quot;3.7&quot;services: app: build: ./ ports: - 80:8080 volumes: - ./:/app environment: - TZ=Asia/Shanghai redis: image: redis:5.0.13 volumes: - redis:/data environment: - TZ=Asia/Shanghaivolumes: redis: 然后运行： 1docker-compose up -d 发布 先登陆 1docker login -u username 新建一个tag 1docker tag test:v1 username/test:v1 push 1docker push username/test:v1","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"Remember the Difference:Cross-Domain Few-Shot Semantic Segmentation via Meta-Memory Transfer","slug":"paper/2023-03-02-Remeber","date":"2023-03-02T05:00:00.000Z","updated":"2023-04-27T10:49:36.530Z","comments":true,"path":"2023/03/02/paper/2023-03-02-Remeber/","link":"","permalink":"http://example.com/2023/03/02/paper/2023-03-02-Remeber/","excerpt":"","text":"original paper: link Abstract we propose an interesting and challenging cross-domain few-shot semantic segmentation task, where the training and test tasks perform on different domains. we propose a meta-memory bank to improve the generalization of the segmentation network by bridging the domain gap between source and target domains we adopt a new contrastive learning strategy to explore the knowledge of different categories during the training stage. Motivation Existing approaches assume that the base training set is sampled from the same domain as the testing set. However, this setting is not always guaranteed. Contribution We propose a novel framework to solve the cross-domain problem in few-shot semantic segmentation. Compared to the standard few-shot segmentation network, we use the most primitive feature transfer to solve the cross-domain problem and effectively broaden the use scenarios of few-shot segmentation tasks. We propose a plug-and-play meta-knowledge module to transfer the prior source distribution to the target do-main. Our model can effectively alleviate the influence of domain shift in few-shot segmentation with exclusive contrastive loss. We demonstrate the effectiveness of our framework on four different cross-domain few-shot segmentation scenarios. In particular, it can achieve state-of-the-art performance under the cross-domain setting. Method Meta-Memory Module function: storing the source data distribution; using meta-knowledge for feature enhancement Memory={M=(mj∈R1×C)j=1N,E=(ej∈R1×C)j=1N}Memory = \\left\\{M = (m_j \\in R^{1 \\times C})_{j=1}^N, E = (e_j \\in R^{1 \\times C})_{j=1}^N \\right\\} Memory={M=(mj​∈R1×C)j=1N​,E=(ej​∈R1×C)j=1N​} for (a): first get input of features of pictures: fb=RC×H×Wf_b = R^{C \\times H \\times W} fb​=RC×H×W then,calculate the mean and variance: μb=1HW∑h=1H∑w=1Wfc,h,w\\mu_b = \\frac{1}{HW}\\sum^H_{h=1}\\sum^W_{w=1}f_{c,h,w} μb​=HW1​h=1∑H​w=1∑W​fc,h,w​ vb=1HW∑h=1H∑w=1W(fc,h,w−μb)2v_b = \\sqrt{\\frac{1}{HW}\\sum^H_{h=1}\\sum^W_{w=1}(f_{c,h,w} - \\mu_b)^2} vb​=HW1​h=1∑H​w=1∑W​(fc,h,w​−μb​)2​ then, normalize: fbform=fb−μbvbf_b^{form} = \\frac{f_b - \\mu_b}{v_b} fbform​=vb​fb​−μb​​ then, calculate the similarity: sMjb=sim(mj,μb)∑b=1Bsim(mj,μb)s_M^{jb} = \\frac{sim(m_j,\\mu_b)}{\\sum^B_{b=1}sim(m_j,\\mu_b)} sMjb​=∑b=1B​sim(mj​,μb​)sim(mj​,μb​)​ sEjb=sim(ej,vb)∑b=1Bsim(ej,vb)s_E^{jb} = \\frac{sim(e_j,v_b)}{\\sum^B_{b=1}sim(e_j,v_b)} sEjb​=∑b=1B​sim(ej​,vb​)sim(ej​,vb​)​ finally, update the Memory: mj=λmj+(1−λ)∑b=1BsMjbμbm_j = \\lambda m_j + (1-\\lambda)\\sum^B_{b=1} s_M^{jb} \\mu_b mj​=λmj​+(1−λ)b=1∑B​sMjb​μb​ ej=λej+(1−λ)∑b=1BsMjbvbe_j = \\lambda e_j + (1-\\lambda)\\sum^B_{b=1} s_M^{jb} v_b ej​=λej​+(1−λ)b=1∑B​sMjb​vb​ the loss is for lower the similarity of each metas: Lorth=12N2(∑i=1N∑j=1NhMij+∑i=1N∑j=1NhEij)L_{orth} = \\frac{1}{2N^2}(\\sum^N_{i=1}\\sum^N_{j=1}h_M^{ij} + \\sum^N_{i=1}\\sum^N_{j=1}h_E^{ij}) Lorth​=2N21​(i=1∑N​j=1∑N​hMij​+i=1∑N​j=1∑N​hEij​) for (b) source data enhance enhanced feature: fbenh=fbnormvbmix+μbmixf_b^{enh} = f_b^{norm} v_b^{mix} + \\mu_b^{mix} fbenh​=fbnorm​vbmix​+μbmix​ where mix are: μbmix=αμb+(1−α)μbM\\mu_b^{mix} = \\alpha \\mu_b + (1-\\alpha)\\mu_b^M μbmix​=αμb​+(1−α)μbM​ vbmix=αvb+(1−α)vbEv_b^{mix} = \\alpha v_b + (1-\\alpha)v_b^E vbmix​=αvb​+(1−α)vbE​ μbM and vbE\\mu_b^M \\ and\\ v_b^E μbM​ and vbE​ are the lowest similarity. target data enhance target data enhance is similar to source data enhance. the difference is $ \\mu_b^M \\ and\\ v_b^E$ are chosen to be max similarity. loss of prototype loss is : Lpro=−1HW∑i=1H∑j=1WYqijlog(R(fqij,pb))L_{pro} = -\\frac{1}{HW}\\sum^H_{i=1}\\sum^W_{j=1} Y_q^{ij}log(R(f_q^{ij},p_b)) Lpro​=−HW1​i=1∑H​j=1∑W​Yqij​log(R(fqij​,pb​)) contrastive loss: Lcont=12B∑i=1B−logpos(i)pos(i)+net(i)L_{cont} = \\frac{1}{2B} \\sum^B_{i=1} -log\\frac{pos(i)}{pos(i) + net(i)} Lcont​=2B1​i=1∑B​−logpos(i)+net(i)pos(i)​ where pos(i)=exp(sim(pbi,pti))pos(i) = exp(sim(p_b^i,p_t^i)) pos(i)=exp(sim(pbi​,pti​)) neg(i)=∑j=1,j≠iB[exp(sim(pbi,pbj))+exp(sim(pbi,ptj))] neg(i) = \\sum^B_{j=1,j \\neq i} [exp(sim(p_b^i,p_b^j))+exp(sim(p_b^i,p_t^j))] neg(i)=j=1,j=i∑B​[exp(sim(pbi​,pbj​))+exp(sim(pbi​,ptj​))] Conclusion a meta-memory module has been proposed to bridge the source and target domains, including reducing the domain gap and enhancing semantic feature representation. Specifically, the meta-memory stores the domain-specific information from the source data during training and transfers them to the target data to improve the generalization of the segmentation model. The memory-based feature enhancement also contributes to discriminative feature learning for the novel classes.","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Few Shot","slug":"Few-Shot","permalink":"http://example.com/tags/Few-Shot/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","permalink":"http://example.com/tags/Semantic-Segmentation/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://example.com/tags/Computer-Vision/"}]},{"title":"Mask Matching Transformer for Few-Shot Segmentation","slug":"paper/2023-02-24-Mask Matching Transformer for Few-Shot Segmentation","date":"2023-02-26T05:00:00.000Z","updated":"2023-04-27T12:45:28.340Z","comments":true,"path":"2023/02/26/paper/2023-02-24-Mask Matching Transformer for Few-Shot Segmentation/","link":"","permalink":"http://example.com/2023/02/26/paper/2023-02-24-Mask%20Matching%20Transformer%20for%20Few-Shot%20Segmentation/","excerpt":"","text":"original paper: link Abstract Typical method learn prototypical features to match query features. They proposed Mask Matching Transformer(MM-Former), a new paradigm. Motivation early method: few to many(the number of support prototypes is typically much less than query features) other method: many to many Overall, the aforementioned approaches construct modules combining the matching operation with segmentation modules and optimizing them jointly. This joint learning fashion not only vastly increases the learning complexity, but also makes it hard to distinguish the effect of matching modules in few-shot segmentation. Contribution We put forward a new perspective for few-shot segmentation, which decouples the learning of matching and segmentation modules, allowing more flexibility and lower training complexity. We introduce a simple two-stage framework named MM-Former that efficiently matches the support samples with a set of query mask proposals to obtain segmentation results. Extensive evaluations on COCO-20i and Pascal-5i demonstrate the potential of the method to be a robust baseline in the few-to-few matching paradigm Method Potential Object Segmenter El+1=TLayerl(El,Fi)E^{l+1} = TLayer^{l}(E^l,F_i) El+1=TLayerl(El,Fi​) ElE^lEl represent the N learnable embeddings before transformer, while El+1E^{l+1}El+1 represents the embeddings after transformer. TLayer denotes a transformer decoder layer. Feature Align Module Learnable Matching Block Final mask is computed as: S=cos(Psgt,PQn)S = cos(P_s^{gt},P_Q^n)S=cos(Psgt​,PQn​) M^=M matmul MLP(S)\\hat{M} = M\\ matmul \\ MLP(S)M^=M matmul MLP(S) Conclusion Our MM-Former introduces the paradigm of decompose first and then blend to the research of few-shot segmentation, which is a totally new perspective and may inspire future researchers to develop more advanced versions. However, there is still a large gap between the current results and the oracle (≈ 20% mIoU). How to further narrow this gap is our future research focus.","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Few Shot","slug":"Few-Shot","permalink":"http://example.com/tags/Few-Shot/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","permalink":"http://example.com/tags/Semantic-Segmentation/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://example.com/tags/Computer-Vision/"}]},{"title":"Compiler Principles -Chapter 2","slug":"compiler-principles/2023-02-22-compiler-principles2","date":"2023-02-22T05:00:00.000Z","updated":"2023-04-27T10:48:14.750Z","comments":true,"path":"2023/02/22/compiler-principles/2023-02-22-compiler-principles2/","link":"","permalink":"http://example.com/2023/02/22/compiler-principles/2023-02-22-compiler-principles2/","excerpt":"","text":"递归规则与递归文法(区别于线性文法) 递归规则 左右具有相同非终结符号的规则 U $\\rightarrow $ Uy 左递归规则 U $\\rightarrow $ xU 右递归规则 U $\\rightarrow $ xUy 自嵌入递归规则 文法的递归性 直接递归：文法中至少包含一条递归规则 间接递归：文法的任一非终结符号经过一步以上推导产生的递归性 文法的递归性原则：文法具有直接递归性或间接递归性，否则无递归性 句型的分析 短语、简单短语、句柄 短语： 如果 ω=xuy\\omega = xuyω=xuy 是一个句型，如果有 z=∗&gt;xUyz=^*&gt;xUyz=∗&gt;xUy，并且 U=+&gt;uU=^+&gt;uU=+&gt;u，U∈Vn,u∈V+U \\in V_n,u \\in V^+U∈Vn​,u∈V+,则u是相对于非终结符号U，句型ω\\omegaω的短语 简单短语： 一步推导可以得到u的话，u就是简单短语 句柄： 句型最左面的简单短语就是句柄 文法的化简与改造 无用产生式的消除 无用产生式：设 G=(Vn,Vt,P,S)G = (V_n,V_t,P,S)G=(Vn​,Vt​,P,S) 是一文法，若G中的符号 x∈Vu∪Vtx \\in V_u \\cup V_tx∈Vu​∪Vt​ 是有用的，则 x 必须满足以下条件，否则 x 就是无用的： 存在 α,β∈V∗\\alpha,\\beta \\in V^*α,β∈V∗，使得$ S=^*&gt;\\alpha x \\beta$ (能被推出来) 存在ω∈Vt∗\\omega \\in V_t^*ω∈Vt∗​，使得 $ \\alpha x \\beta =^*&gt;\\omega$ (能结尾) 算法2.1 满足第二点 得到等价文法 G=(Vn1,Vt,P1,S)G = (V_n^1,V_t,P_1,S)G=(Vn1​,Vt​,P1​,S)，使得对于每个非终结符号都能推出最后的终结符号(们) 置Vn1V_n^1Vn1​和P1P^1P1为空 对P中的每一个产生式A→γA \\rightarrow \\gammaA→γ 若γ∈Vt∗\\gamma \\in V_t^*γ∈Vt∗​，则将A放入Vn1V_n^1Vn1​中。 对于每个产生式A→X1X2...XnA \\rightarrow X_1X_2...X_nA→X1​X2​...Xn​,若 Xi∈VtorXi∈Vn1X_i \\in V_t or X_i \\in V_n^1Xi​∈Vt​orXi​∈Vn1​，将A放入Vn1V_n^1Vn1​中 重复3，直到Vn1V_n^1Vn1​不继续增大 将对应的规则放入P1中P^1中P1中 算法2.2 满足第一点 得到等价文法 G=(Vn′,Vt′,P′,S)G = (V_n^{&#x27;},V_t^{&#x27;},P^{&#x27;},S)G=(Vn′​,Vt′​,P′,S)，使得对于每个非终结符号都能推出最后的终结符号(们) 置3个新的集合为空 将开始符号放入Vn′V_n^{&#x27;}Vn′​中 对于G中任何形如A→α1 or α2 or α3...A \\rightarrow \\alpha_1 \\ or \\ \\alpha_2 \\ or \\ \\alpha_3...A→α1​ or α2​ or α3​...的产生式，如果A∈Vn′A \\in V_n^{&#x27;}A∈Vn′​，则将其中的终结符号和非终结符号分别放入文法对应集合中。 重复3，直到集合不再增大 将对应的规则放入P′P^{&#x27;}P′中 空产生式的消除 简单方法：找到所有能产生空的符号对应替代即可 单产生式的消除 找出能得出单产生式的式子，然后将其替换为对应的结果即可 文法和语言的Chomsky分类 0型文法 α→β\\alpha \\rightarrow \\betaα→β 1型文法（上下文有关文法） α1Aα2→α1βα2\\alpha_1 A \\alpha_2 \\rightarrow \\alpha_1 \\beta \\alpha_2α1​Aα2​→α1​βα2​ 2型文法（上下文无关文法） A→β A∈Vn,β∈V+A \\rightarrow \\beta \\ \\ \\ A\\in V_n,\\beta\\in V^+A→β A∈Vn​,β∈V+ 3型文法 A→aBA \\rightarrow aBA→aB or A→aA \\rightarrow aA→a 右线性正则文法 A→BaA \\rightarrow BaA→Ba or A→aA \\rightarrow aA→a 左线性正则文法","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Compiler Principle","slug":"Compiler-Principle","permalink":"http://example.com/tags/Compiler-Principle/"}]},{"title":"Operating System -Chapter 5","slug":"OS/2023-02-17-OS5","date":"2023-02-17T05:00:00.000Z","updated":"2023-04-27T10:49:19.500Z","comments":true,"path":"2023/02/17/OS/2023-02-17-OS5/","link":"","permalink":"http://example.com/2023/02/17/OS/2023-02-17-OS5/","excerpt":"","text":"I/O控制方式 程序控制I/O 完成一次读写： CPU向控制器发出命令 读入I/O状态，不断循环直到I/O完成 将I/O中的数据读入CPU寄存器 将CPU寄存器写入主存中 CPU干预频率：很频繁，在等待I/O完成过程中需要不断轮询检查 数据传送的单位：Byte 数据流向： 读：I/O设备-&gt;CPU-&gt;内存 写：内存-&gt;CPU-&gt;I/O设备 优劣： 优点：实现简单，可以用软件的方式实现 缺点：CPU和I/O串行工作，CPU利用率低，需要长期“忙等” 中断驱动方式 完成一次读写： CPU向控制器发出命令 读入I/O状态，阻塞该进程，直到I/O完成发出中断信号 将I/O中的数据读入CPU寄存器 将CPU寄存器写入主存中 CPU干预频率：在I/O开始之前和完成之后需要CPU介入，等待I/O的时候可运行别的进程 数据传送单位：Byte 数据流向： 读：I/O设备-&gt;CPU-&gt;内存 写：内存-&gt;CPU-&gt;I/O设备 优劣: 优点：解决了程序直接控制的最大的缺点，CPU不需要不停轮询，CPU利用率得到明显提升 缺点：频繁的中断处理会消耗较多的CPU时间 DMA方式 完成一次读写: CPU给DMA发出命令，给出相应参数，然后CPU做自己的事情 DMA读完/写完数据给CPU发出中断信号 CPU干预频率：传送一个或者多个数据块的开始或者结束的时候，CPU才进行干预 数据传送单位：一个/多个块 数据流向： 读：I/O-&gt;内存 写：内存-&gt;I/O 优劣： 优点：CPU介入频率下降，数据传输增多 缺点：只能读写连续的块，无法离散进行 通道控制方式 通道可以识别并且执行一系列通道命令，可以理解为小型CPU。 完成一次读写： CPU向通道发出I/O指令，指明通道程序的位置以及需要操作的I/O设备，之后CPU切换到其他进程执行 通道执行内存中的通道程序 通道执行规定的任务后，向CPU发出中断信号 CPU干预频率：极低，完成一组数据块的读写后才需要CPU干预 数据传送单位：一组数据块 数据流向： 读：I/O-&gt;内存 写：内存-&gt;I/O 优劣： 优点：资源利用率高 缺点：实现复杂 缓冲 作用 缓解CPU和I/O设备之间速度不匹配的矛盾 减少CPU的中断频率 解决数据粒度不匹配的问题 提高CPU和I/O设备之间的并行性 单缓冲 当用户进程请求某种块设备读入若干块的数据，若采用单缓冲的策略，系统就会在主存中为其分配一个缓冲区 缓冲区不空的时候不能向缓冲区传入数据，只能从缓冲区把数据传出；缓冲区空的时候可以向缓冲区传入数据，但是必须缓冲区充满之后才能传出数据 记 T(传入缓冲区时间),M(传入用户区时间)，C(CPU处理时间) 处理一块平均耗时 max(C,T) + M 双缓冲 内存中设置了两个缓冲区 缓冲池 输入：从空缓冲队列提取一块数据，放到hin中，然后放到输入队列，然后用户从输入队列中取得对应的数据，提取给用户进程 输出：用户从空缓冲队列提取一块数据放到hout,然后放到放到输出队列，然后从输出队列中取得对应的数据 磁盘 磁盘的盘面被可以被分为一个个磁道（圆环），同时也可以分成一个个扇区（扇面），不同的磁盘可以组成柱面. 可以标记为(柱面号，盘面号，扇区号)-&gt;读取地址连续的磁盘块的时候可以减少磁盘移动的时间 磁盘调度算法 先来先服务(FCFS) 优劣： 优点：若请求访问的磁道比较集中，则算法性能良好 缺点：若请求访问的磁道不集中，则算法性能较差 最短寻找时间(SSTF) 思想：每次处理与磁头相距最近的磁道。 优劣： 优点：平均寻道时间最短 缺点：可能导致饥饿 扫描算法 思想：只有移动到最外面才能往内移动，只有移动到最内侧才能往外移动 优劣： 优点：不会饥饿 缺点：响应频率不均匀；只有在最边缘才能改变方向 LOOK调度算法 思想：若当前移动方向上已经没有别的请求，就可以立刻改变磁头移动方向 C-SCAN算法 思想：磁头返回的时候直接返回到起始端 C-LOOK算法 思想：立刻返回到请求的磁道 I/O软件层次结构 用户层软件：与用户交互 设备独立性软件(设备无关性软件):提供提供系统调用的调用接口；实现对设备的保护；差错处理；设备分配与回收；数据缓冲区管理；建立逻辑设备名和物理设备名之间的映射关系 设备驱动程序：负责对设备的具体控制 中断处理程序： 硬件","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Operating System","slug":"Operating-System","permalink":"http://example.com/tags/Operating-System/"}]},{"title":"Operating System -Chapter 6","slug":"OS/2023-02-17-OS6","date":"2023-02-17T05:00:00.000Z","updated":"2023-04-27T10:49:22.550Z","comments":true,"path":"2023/02/17/OS/2023-02-17-OS6/","link":"","permalink":"http://example.com/2023/02/17/OS/2023-02-17-OS6/","excerpt":"","text":"文件分配方式 连续分配 优点：顺序访问容易并且速度快，支持直接存取 缺点：必须要求有连续的存储空间，空间利用率低。必须实现知道文件的长度 文件名 起始块号 长度 … … … 链接分配(隐式) 文件名 起始块号 结束块号 … … … 优点：方便拓展，不会有磁盘脆片问题，外存利用率高 缺点：只支持顺序访问，效率很低 链接分配(显式) 显示链接会包含一个文件分配表将各块的指针存入表中 文件名 开始块号 … … 优点：不会有碎皮，可以随机访问，访问效率高 缺点：FAT文件分配表会占用空间 索引分配 由于链接分配的文件分配表占用空间较多，并且盘块号随机，不能支持高效的随机存取，故所以这里直接将文件所占用的盘块号直接存到索引块中（类似页表） 索引分配同时还有多层索引、混合索引的分配方式 文件储存空间管理 空闲表法 第一个空闲盘块号 空闲块数 … … 空闲链表法 将空闲的盘块/盘区链接成一条链 位视图法 成组链接法 文件共享与保护 文件共享 基于索引结点(硬链接) 对于文件设置索引结点，每次有一个用户就将索引结点的count+1，count&gt;=1的时候说明还有用户要使用，一旦count=0则系统负责删除。 基于符号链(软链接) 共享的文件设置为link文件，记录了主文件的存放路径，相当于快捷方式 文件保护 口令保护 为文件设置一个口令，用户访问的时候必须提供“口令” 优点：保存口令的开销不多，验证口令的时间开销也小 缺点：正确的口令在系统内部，安全性不高 加密保护 使用某个“密码”加密，访问文件的时候需要提供正确的“密码”，系统中保存的文件并不是原始文件而是加密后的文件 优点：保密性强，不需要在系统中储存密码 缺点：编码/译码要花费一定时间 访问控制 系统在FCB/索引结点中增加一个访问控制表，该表可以记录各个用户可以对文件执行哪些操作 可执行的操作包括：读、写、执行、添加、删除、列表清单 将用户分成不同的组，来决定不同组的用户可以对文件执行哪些操作 文件系统层次结构 用户接口:用于处理用户发出的系统调用请求(read,write,open,close等) 文件目录系统:根据文件路径找到对应的FCB和索引结点 存取控制模块：设置文件保护功能，检查用户是否有权限 逻辑文件系统和文件信息缓冲区：将记录号转化为逻辑地址 物理文件系统：把上一层的逻辑地址转化为物理地址 底层 辅助分配模块：分配和回收存储空间 设备管理模块：直接与硬件交互，分配设备等","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Operating System","slug":"Operating-System","permalink":"http://example.com/tags/Operating-System/"}]},{"title":"Operating System -Chapter 4","slug":"OS/2023-02-17-OS4","date":"2023-02-17T05:00:00.000Z","updated":"2023-04-27T10:49:16.120Z","comments":true,"path":"2023/02/17/OS/2023-02-17-OS4/","link":"","permalink":"http://example.com/2023/02/17/OS/2023-02-17-OS4/","excerpt":"","text":"程序的链接和装入 装入方式 绝对装入 提前知道装入模块的首地址并进行修改 静态重定位 装入时将模块装入内存适当的位置，装入时对地址重定位，模块内地址直接相加装入时的头地址。需要连续的储存空间 动态重定位 定义重定位寄存器，其值为开始地址，使用地址时将地址与其相加得到最终地址 链接方式 静态链接 运行之前就将各个模块链接成完整文件 装入时动态链接 在装入内存的时候，边装入边链接 运行时动态链接 在程序执行的时候，需要该模块的时候再链接，便于修改和更新 连续分配管理方式 单一连续分配 将内存分为系统区和用户区，内存中只能驻留一道程序 优点：实现简单，无外部碎片，可利用覆盖技术扩充内存，不一定需要内存保护 缺点：只能单用户，单任务，有外部碎片，内存利用率低 固定分区分配 将用户区分为若干个固定大小的分区，分区的大小可以相等也可以不相等，然后建立一个表项如下： 区号 大小 起始地址 状态 1 2 8 已分配 2 2 10(2+8) 已分配 3 4 12(2+10) 未分配 4 6 16(4+12) 未分配 优点：无外部碎片 缺点：如果程序过大可能无法满足，产生内部碎片 动态分区分配 按照程序的需要动态对内存空间进行分配、回收以及划分，可以用类似上面的表格或者空闲分区链： 动态分区链 双向指针，每个分区的起始和末尾部分指针指向下一块或者上一块内存 分区分配算法 首次适应算法 思想：从低地址开始寻找，直到可分配的大小合适 实现：空闲分区按照地址递增的顺序进行排列方便查询 最佳适应算法 思想：为了尽可能留下大的区间，所以先使用小区间 实现：空闲分区按照容量递增的顺序进行排列 最坏适应算法 思想：解决最佳适应的问题（会产生很多外部碎片），分配的时候选大内存 实现：空闲分区按照容量递减的顺序进行排列 临近适应算法 思想：首次适应算法会使得低地址出现更小的分区 实现：每次分配的时候从上次结束的位置开始查找 基本分页存储管理 页面和页表 31…12 11…0 页号 页偏移 逻辑地址与页号以及页偏移的计算： 页号=逻辑地址页大小页号 = \\frac{逻辑地址}{页大小}页号=页大小逻辑地址​ 页偏移=逻辑地址 mod 页大小页偏移 = 逻辑地址 \\ mod \\ 页大小页偏移=逻辑地址 mod 页大小 地址变换机构 上图是一般的地址变换机构，主要步骤如下： 12345678910P = Add/page_sizeW = Add%page_sizeif P&gt;S return false //越界find_block(F,P) //根据页表起始地址和页号找到对应的块E = b*page_size + W 有了快表之后，则需要稍微更改一下步骤 12345678910111213P = Add/page_sizeW = Add%page_sizeif P&gt;S return false //越界if P in table //如果在快表中找到 E = b*page_size + Welse find_block(F,P) //根据页表起始地址和页号找到对应的块 E = b*page_size + W 二级页表和多级页表 二级页表的分配主要是扩充了一级页表,单个进程可能需要多个页框储存，没有必要让整个页表常驻内存 基本分段存储管理 主要逻辑和分页管理类似，故这里不再赘述 分段分页对比 页是物理单位，对用户不可见，页的大小固定，页表内容是1维的,分页可以提高内存利用率 段是逻辑单位，对用户可见，段的大小不固定，段表的内容是2维的，分段可以满足用户不同的需求 段比页更容易实现信息的共享和保护 段页式存储管理 优点 缺点 分段存储管理 易于实现共享和保护 会有外部碎片 分页存储管理 不会有外部碎片 难以实现共享和保护 故通过段页式存储管理可以使得分段和分页的优势互补，使得既易于实现共享和保护也不会有外部碎片 实现：先将程序进行分段，然后对每个段进行分页 虚拟储存器 特点： 多次性：程序不需要一次全部调入内存 对换性：无需常驻内存，可以换入换出 虚拟性：逻辑上扩充了内存容量 请求分页存储管理 页表项的扩充 由于用到虚拟存储，所以原本的页表已经无法满足当前的需求了，页表指向的块并不一定在内存中 修改后的页表结构如下： 页号 块号 状态位(是否在内存中) 修改位(是否被修改) 访问字段(被访问几次) 外存地址 0 ? 0 0 0 x 1 b 1 0 10 y 2 c 1 1 6 z 地址变换机构 缺页中段机构: 快表(未中)-&gt;慢表(未调入)-&gt;调页，放入快表-&gt;重新查 页面置换算法 最佳置换算法 思想：每次淘汰页面的时候，选择永远不使用的页面或者是最长时间不访问的(无法实现，you can’t see the future) 先进先出 思想：先进入内存的页面先被淘汰（淘汰最早进入内存的页面） 评价： 优点：实现简单 缺点：算法性能差，可能会出现Belady异常 Belady异常：当为进程分配的物理块增多的时候，缺页次数不降反增的异常现象 最长最久未使用(see the future from the history) 思想：记录页面自访问以来所经历的时间t，淘汰的时候选择t最大的 淘汰 评价： 优点：算法性能好 缺点：实现困难，开销大 时钟置换算法 思想：为页面设置访问位，0为未访问，1为访问，循环扫描，如果遇到的是1则置为0，继续扫描，遇到的是0则淘汰该页面 改进：加(访问位，修改位) 轮数 如何修改 淘汰 1 不修改任何标识位 (0,0) 2 将扫描过的访问位设置为0 (0,1) 3 不修改任何标志位 (0,0) 4 不修改任何标志位 (0,1)","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Operating System","slug":"Operating-System","permalink":"http://example.com/tags/Operating-System/"}]},{"title":"Operating System -Chapter 2","slug":"OS/2023-02-15-OS2","date":"2023-02-16T05:00:00.000Z","updated":"2023-04-27T10:49:03.010Z","comments":true,"path":"2023/02/16/OS/2023-02-15-OS2/","link":"","permalink":"http://example.com/2023/02/16/OS/2023-02-15-OS2/","excerpt":"","text":"经典进程同步问题 生产者-消费者问题 问题描述 一群生产者进程在生产数据，并将此数据提供给一群消费者进程去消费处理 为使二者可以并发执行，在它们之间设置了一个具有n个缓冲区的循环缓冲，生产者进程可以将它所生产的数据放入一个缓冲区中，消费者进程可以从一个缓冲区中取得一个数据消费 异步运行方式及彼此必须保持同步 问题解析 空缓冲区与满缓冲区 空缓冲区是指未投放数据或虽曾投放数据但对应数据已被取走的缓冲区 满缓冲区则指已投放数据且对应数据尚未被取走的缓冲区 进程同步 当生产者进程要把所生产的数据送入循环缓冲时，首先应检查是否有空缓冲区存在，若有，则可向对应空缓冲区中投放数据，同时通知消费者进程；否则只有等待。 当消费者进程要从循环缓冲中提取数据时，首先应检查是否有满缓冲区存在，若有，则从对应满缓冲区中提取数据，并通知生产者进程，否则只有等待。 进程互斥 缓冲区及其“指针”是临界资源：多个生产者/消费者进程 解决方法 互斥信号量：临界区的指针，针对于多生产者同时向一个地方放东西 同步信号量：只有生产者生产了东西，消费者才能消费；消费者同理 123456789101112131415161718192021222324252627282930semaphore mutex = 1 //互斥semaphore empty = n //同步semaphore full = 0 //同步producer()&#123; while(1)&#123; 生产产品 P(empty) //检查是否空 P(mutex) /*注意，不能将上面两个P操作颠倒 如果颠倒，假如有一个生产者进程先进来，但是没有空的内容，然后这是有又有一个消费者进来，但是他会被卡在mutex那里，这样就导致死锁了 */ 放入缓冲区 V(mutex) V(full) //增加一个产品 &#125;&#125;consumer()&#123; while(1)&#123; P(full) //检查是否有东西可以用 P(mutex) 消耗产品 V(mutex) V(empty) //增加一个空的缓冲区 使用产品 &#125;&#125; 衍生问题 多生产者-多消费者问题 桌子上有一个盘子，每次只能放一个水果，父亲专门放苹果，母亲专门放橘子，儿子专门吃苹果，女儿专门吃橘子。 生产者和消费者生产的东西可能不一样。 互斥：缓冲区（盘子）要互斥访问 同步： 父亲将苹果放入盘子后，儿子才能吃 母亲将橘子放入盘子后，女儿才能吃 儿子/女儿吃完水果后，父亲/母亲才能访问盘子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849semaphore mutex = 1 //互斥semaphore apple = 0 //同步semaphore orange = 0 //同步semaphore plate = 1 //同步dad()&#123; while(1)&#123; 准备苹果 P(plate) P(mutex) V(apple) 放入盘子 V(mutex) &#125;&#125;mom()&#123; while(1)&#123; 准备橘子 P(plate) P(mutex) 放入盘子 V(orange) V(mutex) &#125;&#125;daughter()&#123; while(1)&#123; P(orange) P(mutex) 取出橘子 V(mutex) V(plate) 吃掉 &#125;&#125;son()&#123; while(1)&#123; P(apple) P(mutex) 取出苹果 V(mutex) V(plate) 吃掉 &#125;&#125; 吸烟者问题 一个系统有三个抽烟者进程和一个供应者进程，抽烟者不停卷烟然后抽掉它，每次卷烟需要有三种材料：烟草，纸，胶水。三个抽烟者中，他们分别拥有烟草、纸、胶水，供应者无限供应三种材料，每次将两种个材料放到桌子上然后有一个抽烟者卷烟并且抽掉，并且给供应者完成信号，供应则会就会再次放材料到桌子上，这个过程不断重复。 互斥:桌子是缓冲区，需要互斥进行 同步: 组合一：第一个抽烟者取走东西 组合二：第二个抽烟者取走东西 组合三：第三个抽烟者取走东西 抽完烟发出信号，供应者送下一个组合 12345678910111213141516171819202122232425262728293031323334353637383940semaphore mutex = 1 //互斥semaphore offer1 = 0 //同步semaphore offer2 = 0 //同步semaphore offer3 = 0 //同步semaphore finish = 0 //同步int i = 0provider()&#123; while(1)&#123; if(i==1)&#123; V(offer1) &#125;else if(i==2)&#123; V(offer2) &#125;else if(i==3)&#123; V(offer3) &#125; i = (i+1)%3 //使得三个抽烟者都可以抽 P(finish) &#125;&#125;smoker1()&#123; while(1)&#123; P(offer1) V(finish) &#125;&#125;smoker2()&#123; while(1)&#123; P(offer2) V(finish) &#125;&#125;smoker3()&#123; while(1)&#123; P(offer3) V(finish) &#125;&#125; 读者-写者问题 问题描述 读者—写者问题是指保证任何写者进程必须与其它进程互斥地访问共享数据对象（数据文件或记录）的同步问题。 存在多个进程共享一个数据对象 只要求读的进程称为读者进程 拥有写或修改要求的进程称为写者进程 允许多个读者进程同时执行读操作 任何写者进程的执行具有排它性 读者—写者问题常用于测试新同步原语 问题解析 同步： 互斥：写进程-写进程 写进程-读进程 读-读之间没有互斥 解决方法 123456789101112131415161718192021222324semaphore rw = 1int count = 0writer()&#123; while(1)&#123; P(rw) 写 V(rw) &#125;&#125;reader()&#123; while(1)&#123; if(count == 0) P(rw) count++ 读 count-- if(count==0) V(rw) &#125;&#125; 衍生问题 两个读进程一起会阻塞在P(rw)上，这是因为对count的判断不是原语，需要设置另一个信号量来防止这种情况，即人为创造一个原语 12345678910111213141516semaphore mutex = 1reader()&#123; while(1)&#123; P(mutex) if(count==0) P(rw) count++ V(mutex) 读 P(mutex) count-- if(count==0) V(rw) V(mutex) &#125;&#125; 如果有源源不断的读进程，会导致写进程阻塞饿死,此时需要一个新的信号量来使得两者公平竞争 1234567891011121314151617181920212223242526272829semaphore w = 1writer()&#123; while(1)&#123; P(w) P(rw) V(rw) V(w) &#125;&#125;reader()&#123; while(1)&#123; P(w) P(mutex) if(count==0) P(rw) count++ V(mutex) V(w) 读 P(mutex) count-- if(count==0) V(rw) V(mutex) &#125;&#125; 写者优先，即无论如何都需要写者插队 12345678910111213141516171819202122232425262728293031323334353637semaphore mutex2 = 1writer()&#123; while(1)&#123; P(mutex2) if (writercount==0) P(w) writercount++ V(mutex2) P(rw) 写 V(rw) P(mutex2) writercount-- if(writercount==0) V(w) V(mutex2) &#125;&#125;reader()&#123; while(1)&#123; P(w) P(mutex) if(count==0) P(rw) count++ V(mutex) V(w) 读 P(mutex) count-- if(count==0) V(rw) V(mutex) &#125;&#125; 读者限定的读者-写者问题 设置一个信号量表示最大人数即可 12345678910semaphore num = nreader()&#123; while(1)&#123; P(num) 读者代码 V(num) &#125;&#125; 哲学家进餐问题 问题描述 五个哲学家共用一张圆桌，分别坐在环桌均匀摆放的五张椅子上，并全部奉行交替地进行思考和进餐的生活方式 圆桌上放有五支筷子，均匀排放在哲学家之间的位置上 哲学家饥饿时便试图去取用圆桌上最靠近他左右两端的两支筷子，且只有在同时拿到两支筷子时方可进餐，进餐完毕则把筷子放回原处，并继续进行思考 问题解析 互斥：每个哲学家和旁边的哲学家都对他们中间的筷子访问互斥 该问题只有互斥，没有同步 解决方法 123456789101112semaphore chopstick[5]=&#123;1,1,1,1,1&#125;Pi()&#123; while(1)&#123; P(chopstick[i]) P(chopstick[(i+1)%5]) 吃饭 V(chopstick[i]) V(chopstick[(i+1)%5]) 思考 &#125;&#125; 但是上述方法有一个问题，如果都拿一根会导致死锁. 可以添加限制： 只能允许4个哲学家同时用餐 奇数号哲学家先拿左面筷子，偶数号哲学家先拿右面筷子 哲学家左右两只筷子都可以使用的时候才允许取筷子 1234567891011121314semaphore chostick[5] = &#123;1,1,1,1,1&#125;semaphore mutex = 1Pi()&#123; while(1)&#123; P(mutex) P(chopsitck[i]) P(chopstick[(i+1)%5]) V(mutex) 吃饭 V(chopsitck[i]) V(chopstick[(i+1)%5]) &#125;&#125;","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Operating System","slug":"Operating-System","permalink":"http://example.com/tags/Operating-System/"}]},{"title":"Operating System -Chapter 3","slug":"OS/2023-02-16-OS3","date":"2023-02-16T05:00:00.000Z","updated":"2023-04-27T10:49:06.350Z","comments":true,"path":"2023/02/16/OS/2023-02-16-OS3/","link":"","permalink":"http://example.com/2023/02/16/OS/2023-02-16-OS3/","excerpt":"","text":"数学符号（评价指标） CPU利用率=忙时总时长CPU利用率=\\frac{忙时}{总时长}CPU利用率=总时长忙时​ 吞吐量=总作业总时长吞吐量 = \\frac{总作业}{总时长}吞吐量=总时长总作业​ 周转时间=完成时间−提交时间周转时间 = 完成时间-提交时间周转时间=完成时间−提交时间 平均周转时间=各个作业周转时间之和作业数平均周转时间= \\frac{各个作业周转时间之和}{作业数}平均周转时间=作业数各个作业周转时间之和​ 带权周转时间=周转时间实际运行时间带权周转时间 = \\frac{周转时间}{实际运行时间}带权周转时间=实际运行时间周转时间​ 平均带权周转时间=各个作业带权周转时间之和作业数平均带权周转时间 = \\frac{各个作业带权周转时间之和}{作业数}平均带权周转时间=作业数各个作业带权周转时间之和​ 调度算法 先来先服务算法（FCFS） 基本思想 先来先服务作业调度 先来先服务进程调度 算法特点 优点：公平，实现简单 缺点：对于长作业有利，对于短作业则不利，因为可能由于长作业先到而导致短作业一直无法得到处理 短作业优先算法（SJF) 基本思想 最少的平均等待时间，最少的平均周转时间 算法特点 优点：最短的平均等待时间周转时间 缺点：对短作业有利，对长作业不利，因为有可能短作业太多导致长作业饥饿 高优先权优先调度算法 基本思想 照顾紧迫性作业 算法分类 非抢占式优先权算法 抢占式优先权算法 算法特点 优点：可以自行调整进程顺序 缺点：可能会导致饥饿 高相应比优先算法 响应比=等待时间+要求服务时间要求服务时间响应比 = \\frac{等待时间+要求服务时间}{要求服务时间}响应比=要求服务时间等待时间+要求服务时间​ 基本思想 综合考虑 算法特点 综合考虑情况 时间片轮转算法 基本思想 先来先服务原则排队 时间片以及时钟中断 算法特点 优点：公平，响应快 缺点：进程切换有一定的开销 多级反馈队列算法 规则 设置多级就绪队列，队列优先级从高到低，时间片从小到大 新进程进入第一级，在时间片结束后进入下一级队列的队尾 只有当上一级队列为空的时候才给当前队列分配时间片 算法特点 平衡各种优缺点 死锁 产生条件 互斥： 对互斥使用的资源的争抢才会产生死锁 不剥夺条件：资源未适用之前不能夺走，只能主动释放 请求和保持：进程已经保持一个资源，又提出新的资源请求，但是该资源又被占 循环等待链：各个进程等待别的进程的资源，最后形成一个循环链 处理方法 预防死锁 避免死锁 检测和解除 预防死锁 破坏不剥夺条件 当进程请求的资源不满足时，立刻释放保持的资源 某进程资源被其他资源占有的时候，通过操作系统进行剥夺 缺点： 实现复杂 只适用于易于保存的资源 增加开销 可能会导致饥饿，因为资源会被剥夺 破坏请求和保持条件 运行前将所有的资源一次分配好 缺点：资源利用率低 破坏循环等待条件 给资源进行编号，按照编号进行申请 缺点： 加设备的时候很难处理 导致系统资源的浪费 用户编程实现复杂麻烦 避免死锁（银行家算法） 安全序列：系统按照这个序列分配资源，每个进程都可以顺利完成，如果分配后无安全序列，则系统进入了不安全状态 银行家算法 1234567891011121314151617181920212223242526272829/*进程P申请资源request此时系统有的资源是available进程P还需要的资源是need*/if request &gt; need return falseif request &gt; available //P进程应该等待//试探满足P的需求available = available - request //空闲的减少，因为被分配了allocation = allocation + request //已经分配的增加need = need - request //need减少//执行安全性算法检测是否安全work = available finish = false//在进程中找到满足finish=false即没有分配资源的，need&lt;work即目前资源足够给他分配for p in process: if p.finish = false and p.need &lt; work work = work + allocation //将进程对应分配的资源归还 p.finish = trueif finish = true //所有进程的finish都是真，则为安全序列 return safeelse return not safe 死锁的检测和解除 资源分配图 两个粉色的圆形表示进程，矩形表示不同类型的资源，圆形指向矩形的箭头表示向该资源申请资源，矩形指向圆形的箭头表示已经分配了的资源。 如果能消除所有的边则表示无死锁。 算法： 找出不阻塞并且不是孤立点的P，对其进行释放 重复 1 如果可以消除所有的边，则没有死锁，否则有死锁","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Operating System","slug":"Operating-System","permalink":"http://example.com/tags/Operating-System/"}]},{"title":"Compiler Principles -Chapter 5","slug":"compiler-principles/2023-02-15-compiler-principles","date":"2023-02-15T05:00:00.000Z","updated":"2023-04-27T10:48:43.900Z","comments":true,"path":"2023/02/15/compiler-principles/2023-02-15-compiler-principles/","link":"","permalink":"http://example.com/2023/02/15/compiler-principles/2023-02-15-compiler-principles/","excerpt":"","text":"布尔表达式 E→iE \\rightarrow iE→i 1234E.TC = NXQE.FC = NXQ+1Gen(JNZ,entry(i),0,0)Gen(J,_,_,0) E→i1ropi2E \\rightarrow i^{1} rop i^{2}E→i1ropi2 1234E.TC = NXQE.FC = NXQ+1Gen(J_rop,entry(i1),entry(i2),0)Gen(J,_,_,0) E→(E1)E \\rightarrow (E^{1})E→(E1) 12E.TC = E1.TCE.FC = E1.FC E→ E1E \\rightarrow ~E^1E→ E1 12E.TC = E1.FCE.FC = E1.TC EA→E1∧E^A \\rightarrow E^1 \\landEA→E1∧ 假如E为真的话就还需要继续看第二个E是否为真，所以需要回填地址。 而假如E为假的话就不需要继续看了，可以直接得结果，所以直接给E A 12BackPatch(E_1.TC,NXQ)E_A.FC = E_1.FC E→EAE2E \\rightarrow E^AE^2E→EAE2 E的真出口只能是第二个E为真得到的 E的假出口就需要将两个E的假出口合并 12E.TC = E_2.TCE.FC = Merge(E_A.FC, E_2.FC) Eo→E1∨E^o \\rightarrow E^1 \\lorEo→E1∨ 12BackPatch(E_1.FC,NXQ)E_o.TC = E_1.TC E→EoE2E \\rightarrow E^oE^2E→EoE2 12E.TC = Merge(E_o.TC,E_2.TC)E.FC = E_2.FC 条件语句和循环语句 C→if E thenC \\rightarrow if \\ E \\ thenC→if E then 当E为真的时候需要执行下一条语句所以要回填 E为假的时候需要给C的chain从而判断下一条语句要到哪里执行 12BackPatch(E.TC,NXQ)C.chain = E.FC TP→CS1 elseT^P \\rightarrow CS^1 \\ elseTP→CS1 else q用于：假如if为真，执行之后应该跳出if语句，而不是执行else后面的语句，故生成一条无条件跳转指令跳转到最后 将下一条语句回填给C.chain，使得C.chain找到else语句的内容 将S_1.chain和q连接起来表示，执行完当前语句后应该跳到else语句之后 1234q = NXQGen(J,_,_,0)BackPatch(C.chain,NXQ)T_p.chain = Merge(S_1.chain,q) S→TP S2S \\rightarrow T^P \\ S^2S→TP S2 最后的chain是将T_p和S_2的chain连接起来 1S.chain = Merge(T_p.chain,S_2.chain) S→CS1S \\rightarrow CS^1S→CS1 这里的S表示没有else的处理情况 1S.chain = Merge(C.chian,S_1.chain) W→whileW \\rightarrow whileW→while 由于while语句会回到开头，故这里保存了第一条语句的位置，即开头 1W.quad = NXQ Wd→W E doW^d \\rightarrow W \\ E \\ doWd→W E do 假如E为真，则需要执行下一条语句 假如E为假，则需要判断下一条语句的位置，故给了W_d.chain 这里将W的四元式给W_d主要是为了保存信息以便之后用 123BackPatch(E.TC,NXQ)W_d.chain = E.FCW_d.QUAD = W.QUAD S→WdS1S \\rightarrow W^dS^1S→WdS1 给S_1.chain W_d的四元式的目的是防止出现跳转为0的地方 S.chain表示结尾，即E为假的时候到的地方，即W_d.chain 123BackPatch(S_1.chain,W_d.QUAD)Gen(j,_,_,W_d.QUAD)S.chain = W_d.chain S→begin L endS \\rightarrow begin \\ L \\ endS→begin L end 1S.chain = L.chain S→AS \\rightarrow AS→A 1S.chain = 0 L→LsS1L \\rightarrow L^sS^1L→LsS1 1L.chain = S_1.chain L→SL \\rightarrow SL→S 1L.chain = S.chain Ls→LL^s \\rightarrow LLs→L 1BackPatch(L.chain,NXQ)","categories":[{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"Compiler Principle","slug":"Compiler-Principle","permalink":"http://example.com/tags/Compiler-Principle/"}]}],"categories":[{"name":"notes","slug":"notes","permalink":"http://example.com/categories/notes/"},{"name":"study","slug":"study","permalink":"http://example.com/categories/study/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://example.com/tags/notes/"},{"name":"tools","slug":"tools","permalink":"http://example.com/tags/tools/"},{"name":"Computer Network","slug":"Computer-Network","permalink":"http://example.com/tags/Computer-Network/"},{"name":"Few Shot","slug":"Few-Shot","permalink":"http://example.com/tags/Few-Shot/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","permalink":"http://example.com/tags/Semantic-Segmentation/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://example.com/tags/Computer-Vision/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"Compiler Principle","slug":"Compiler-Principle","permalink":"http://example.com/tags/Compiler-Principle/"},{"name":"Operating System","slug":"Operating-System","permalink":"http://example.com/tags/Operating-System/"}]}